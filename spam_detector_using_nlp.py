# -*- coding: utf-8 -*-
"""Spam-Detector-using-nlp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OkW2HIfKQR-1-wUmNBA0BSt1s-6sNRuE
"""

!pip install anvil-uplink

import anvil.server

anvil.server.connect("6I7QELWOTF5RYCXSYW2N2XEF-YLGBYHVTXYTSLCAW")

# Commented out IPython magic to ensure Python compatibility.


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
from sklearn.model_selection import train_test_split

data = pd.read_csv('/content/spam_ham_dataset.csv')
data.head()

def getSubject(email):
    subject = email[0:email.find('\r\n')]
    subject = subject. replace('Subject: ', '')
    return subject

def getBody(email):
    body = email[email.find('\r\n')+2:]
    return body

data = data.drop(['Unnamed: 0', 'label'], axis=1)

data['subject'] = data['text'].apply(lambda x: getSubject(x))
data['body'] = data['text'].apply(lambda x: getBody(x))

data = data.drop(['text'], axis=1)

data

X = data['subject']+' '+data['body']
Y = data['label_num']

X

import nltk
nltk.download('punkt')

from nltk.corpus import stopwords
nltk.download('stopwords')

nx = []

for sent in X:
  words = nltk.word_tokenize(sent)
  words = [word for word in words if word.isalnum()]
  words = [word for word in words if word not in set(stopwords.words("english"))]
  nx.append(words)

nx

ne = []
for st in nx:
  s= ' '.join([str(item) for item in st])
  ne.append(s)
ne

x_train,x_test, y_train, y_test = train_test_split(ne,Y, stratify=Y, test_size=0.25, random_state=42)

from sklearn.feature_extraction.text import CountVectorizer
vec = CountVectorizer(stop_words='english')

x_train= vec.fit_transform(x_train).toarray()
x_test = vec.transform(x_test).toarray()

x_train

x_test

"""## Naive bayes Classifier"""

from sklearn.naive_bayes import MultinomialNB

model = MultinomialNB()
model.fit(x_train,y_train)

predictions = model.predict(x_test)
print(predictions)

plt.plot(predictions)
plt.show()

from sklearn import metrics
print(metrics.confusion_matrix(y_test,predictions))

print(metrics.classification_report(y_test,predictions))

metrics.accuracy_score(y_test, predictions)

"""## SVM Classifier"""

# from sklearn.svm import LinearSVC
# model2 = LinearSVC()
# model2.fit(x_train,y_train)

# predictions = model2.predict(x_test)
# print(predictions)

# plt.plot(predictions)
# plt.show()

# from sklearn import metrics
# print(metrics.confusion_matrix(y_test,predictions))

# print(metrics.classification_report(y_test,predictions))

metrics.accuracy_score(y_test, predictions)

"""##Decision Tree Classifier"""

# from sklearn.tree import DecisionTreeClassifier
# from sklearn import tree

# model3 = tree.DecisionTreeClassifier(criterion = 'entropy', random_state = 0)
# model3.fit(x_train,y_train)

# predictions = model3.predict(x_test)
# print(predictions)

# plt.plot(predictions)
# plt.show()

# from sklearn import metrics
# print(metrics.confusion_matrix(y_test,predictions))

# print(metrics.classification_report(y_test,predictions))

metrics.accuracy_score(y_test, predictions)

# print(model.predict(vec.transform([''])))

@anvil.server.callable
def predict(message):
  classification = model.predict(vec.transform([message]))
  return classification

anvil.server.wait_forever()